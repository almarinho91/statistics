{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Methods\n",
    "\n",
    "Implementation of various classification algorithms including Logistic Regression, Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), and K-Nearest Neighbors (KNN).\n",
    "\n",
    "## Contents\n",
    "1. Data Loading and Exploration\n",
    "2. Logistic Regression\n",
    "3. Model Evaluation and Confusion Matrix\n",
    "4. Cross-Validation\n",
    "5. Linear Discriminant Analysis (LDA)\n",
    "6. Quadratic Discriminant Analysis (QDA)\n",
    "7. K-Nearest Neighbors (KNN)\n",
    "8. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Smarket Dataset\n",
    "\n",
    "Stock market data with daily percentage returns for the S&P 500 over a 5-year period (2001-2005)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Smarket dataset\n",
    "url = \"https://raw.githubusercontent.com/selva86/datasets/master/Smarket.csv\"\n",
    "Smarket = pd.read_csv(url)\n",
    "\n",
    "print(f\"Dataset shape: {Smarket.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(Smarket.columns.tolist())\n",
    "Smarket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset summary\n",
    "print(\"Summary Statistics:\")\n",
    "Smarket.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data Info:\")\n",
    "print(Smarket.info())\n",
    "print(f\"\\nTarget variable distribution:\")\n",
    "print(Smarket['Direction'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix (exclude Direction which is categorical)\n",
    "numeric_cols = Smarket.select_dtypes(include=[np.number]).columns\n",
    "correlation = Smarket[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey observation: Low correlation between Today and Lag1-5\")\n",
    "print(\"This suggests past returns have little predictive power for future returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume trend over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(Smarket['Volume'], alpha=0.7)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Volume')\n",
    "plt.title('Trading Volume Over Time (Increasing Trend)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Binary classification: Predict market direction (Up/Down) based on previous days' returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = Smarket[['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
    "y = (Smarket['Direction'] == 'Up').astype(int)  # Up=1, Down=0\n",
    "\n",
    "# Fit logistic regression\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X, y)\n",
    "\n",
    "print(\"Logistic Regression Coefficients:\")\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': log_reg.coef_[0]\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "print(coef_df)\n",
    "print(f\"\\nIntercept: {log_reg.intercept_[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and probabilities\n",
    "y_pred = log_reg.predict(X)\n",
    "y_probs = log_reg.predict_proba(X)[:, 1]  # Probability of Up\n",
    "\n",
    "print(\"First 10 predictions:\")\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y[:10].values,\n",
    "    'Predicted': y_pred[:10],\n",
    "    'Prob(Up)': y_probs[:10]\n",
    "})\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Training Data')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(f\"\\nTraining Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training Error Rate: {1 - accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred, target_names=['Down', 'Up']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: Train/Test Split\n",
    "\n",
    "Train on years 2001-2004, test on year 2005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split based on year\n",
    "train_mask = Smarket['Year'] < 2005\n",
    "test_mask = Smarket['Year'] >= 2005\n",
    "\n",
    "X_train = X[train_mask]\n",
    "X_test = X[test_mask]\n",
    "y_train = y[train_mask]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"\\nTest set year distribution:\")\n",
    "print(Smarket[test_mask]['Year'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on training data\n",
    "log_reg_cv = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_test = log_reg_cv.predict(X_test)\n",
    "y_probs_test = log_reg_cv.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Confusion matrix for test data\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Test Data (2005)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Error Rate: {1 - test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: Using Only Lag1 and Lag2\n",
    "\n",
    "Remove predictors with high p-values to reduce variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only Lag1 and Lag2 (lowest p-values from full model)\n",
    "X_reduced = Smarket[['Lag1', 'Lag2']]\n",
    "X_train_red = X_reduced[train_mask]\n",
    "X_test_red = X_reduced[test_mask]\n",
    "\n",
    "# Fit model\n",
    "log_reg_red = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_red.fit(X_train_red, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_red = log_reg_red.predict(X_test_red)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_red = confusion_matrix(y_test, y_pred_red)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_red, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Reduced Model (Lag1 + Lag2)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "test_accuracy_red = accuracy_score(y_test, y_pred_red)\n",
    "print(f\"\\nTest Accuracy (Reduced Model): {test_accuracy_red:.4f}\")\n",
    "print(f\"Improvement: {test_accuracy_red - test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for new data\n",
    "new_data = pd.DataFrame({\n",
    "    'Lag1': [1.2, 1.5],\n",
    "    'Lag2': [1.1, -0.8]\n",
    "})\n",
    "\n",
    "predictions = log_reg_red.predict(new_data)\n",
    "probabilities = log_reg_red.predict_proba(new_data)[:, 1]\n",
    "\n",
    "print(\"Predictions for new data:\")\n",
    "results = pd.DataFrame({\n",
    "    'Lag1': new_data['Lag1'],\n",
    "    'Lag2': new_data['Lag2'],\n",
    "    'Prediction': ['Up' if p == 1 else 'Down' for p in predictions],\n",
    "    'Prob(Up)': probabilities\n",
    "})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA)\n",
    "\n",
    "Alternative to logistic regression for binary and multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train_red, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lda = lda.predict(X_test_red)\n",
    "y_probs_lda = lda.predict_proba(X_test_red)\n",
    "\n",
    "print(\"LDA Model Parameters:\")\n",
    "print(f\"Priors: {lda.priors_}\")\n",
    "print(f\"\\nClass means:\")\n",
    "print(pd.DataFrame(lda.means_, columns=['Lag1', 'Lag2'], index=['Down', 'Up']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for LDA\n",
    "cm_lda = confusion_matrix(y_test, y_pred_lda)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_lda, annot=True, fmt='d', cmap='Purples',\n",
    "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - LDA')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "lda_accuracy = accuracy_score(y_test, y_pred_lda)\n",
    "print(f\"\\nLDA Test Accuracy: {lda_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior probabilities\n",
    "print(\"First 20 posterior probabilities (Down class):\")\n",
    "print(y_probs_lda[:20, 0])\n",
    "print(\"\\nFirst 20 predictions:\")\n",
    "print(['Up' if p == 1 else 'Down' for p in y_pred_lda[:20]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis (QDA)\n",
    "\n",
    "Allows for non-linear decision boundaries between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit QDA\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train_red, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_qda = qda.predict(X_test_red)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_qda = confusion_matrix(y_test, y_pred_qda)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_qda, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - QDA')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "qda_accuracy = accuracy_score(y_test, y_pred_qda)\n",
    "print(f\"\\nQDA Test Accuracy: {qda_accuracy:.4f}\")\n",
    "print(f\"Improvement over LDA: {qda_accuracy - lda_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN with K=1\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn1.fit(X_train_red, y_train)\n",
    "y_pred_knn1 = knn1.predict(X_test_red)\n",
    "\n",
    "cm_knn1 = confusion_matrix(y_test, y_pred_knn1)\n",
    "knn1_accuracy = accuracy_score(y_test, y_pred_knn1)\n",
    "\n",
    "print(f\"KNN (K=1) Test Accuracy: {knn1_accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_knn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN with K=3\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn3.fit(X_train_red, y_train)\n",
    "y_pred_knn3 = knn3.predict(X_test_red)\n",
    "\n",
    "cm_knn3 = confusion_matrix(y_test, y_pred_knn3)\n",
    "knn3_accuracy = accuracy_score(y_test, y_pred_knn3)\n",
    "\n",
    "print(f\"KNN (K=3) Test Accuracy: {knn3_accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm_knn3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results_comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression (All)', 'Logistic Regression (Lag1+Lag2)', \n",
    "              'LDA', 'QDA', 'KNN (K=1)', 'KNN (K=3)'],\n",
    "    'Test Accuracy': [\n",
    "        test_accuracy,\n",
    "        test_accuracy_red,\n",
    "        lda_accuracy,\n",
    "        qda_accuracy,\n",
    "        knn1_accuracy,\n",
    "        knn3_accuracy\n",
    "    ]\n",
    "}).sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(results_comparison.to_string(index=False))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(results_comparison['Model'], results_comparison['Test Accuracy'], color='skyblue')\n",
    "plt.xlabel('Test Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xlim([0.4, 0.65])\n",
    "for i, v in enumerate(results_comparison['Test Accuracy']):\n",
    "    plt.text(v + 0.005, i, f'{v:.3f}', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caravan Insurance Dataset\n",
    "\n",
    "Predicting whether customers will purchase caravan insurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Caravan dataset\n",
    "try:\n",
    "    url_caravan = \"https://raw.githubusercontent.com/selva86/datasets/master/Caravan.csv\"\n",
    "    Caravan = pd.read_csv(url_caravan)\n",
    "    print(f\"Dataset shape: {Caravan.shape}\")\n",
    "    \n",
    "    # Check target variable\n",
    "    print(f\"\\nPurchase distribution:\")\n",
    "    print(Caravan['Purchase'].value_counts())\n",
    "    print(f\"\\nPurchase rate: {Caravan['Purchase'].value_counts(normalize=True)['Yes']:.1%}\")\n",
    "    \n",
    "except:\n",
    "    print(\"Could not load Caravan dataset. Skipping this section.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Standardize features to have mean=0 and variance=1. Critical for KNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Caravan' in locals():\n",
    "    # Separate features and target\n",
    "    X_caravan = Caravan.drop('Purchase', axis=1)\n",
    "    y_caravan = (Caravan['Purchase'] == 'Yes').astype(int)\n",
    "    \n",
    "    # Check variance before scaling\n",
    "    print(\"Before scaling:\")\n",
    "    print(f\"Variance of first feature: {X_caravan.iloc[:, 0].var():.4f}\")\n",
    "    print(f\"Variance of second feature: {X_caravan.iloc[:, 1].var():.4f}\")\n",
    "    print(f\"Mean of first feature: {X_caravan.iloc[:, 0].mean():.4f}\")\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_caravan_scaled = scaler.fit_transform(X_caravan)\n",
    "    X_caravan_scaled = pd.DataFrame(X_caravan_scaled, columns=X_caravan.columns)\n",
    "    \n",
    "    print(\"\\nAfter scaling:\")\n",
    "    print(f\"Variance of first feature: {X_caravan_scaled.iloc[:, 0].var():.4f}\")\n",
    "    print(f\"Variance of second feature: {X_caravan_scaled.iloc[:, 1].var():.4f}\")\n",
    "    print(f\"Mean of first feature: {X_caravan_scaled.iloc[:, 0].mean():.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Caravan' in locals():\n",
    "    # Train/test split: first 1000 as test\n",
    "    X_train_car = X_caravan_scaled.iloc[1000:]\n",
    "    X_test_car = X_caravan_scaled.iloc[:1000]\n",
    "    y_train_car = y_caravan.iloc[1000:]\n",
    "    y_test_car = y_caravan.iloc[:1000]\n",
    "    \n",
    "    print(f\"Training set size: {len(X_train_car)}\")\n",
    "    print(f\"Test set size: {len(X_test_car)}\")\n",
    "    print(f\"\\nBaseline (predict No for all): {(y_test_car == 0).mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on Caravan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Caravan' in locals():\n",
    "    # KNN with different K values\n",
    "    k_values = [1, 2, 3, 5]\n",
    "    \n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train_car, y_train_car)\n",
    "        y_pred = knn.predict(X_test_car)\n",
    "        \n",
    "        cm = confusion_matrix(y_test_car, y_pred)\n",
    "        error_rate = 1 - accuracy_score(y_test_car, y_pred)\n",
    "        \n",
    "        # True Positive Rate (for those who buy)\n",
    "        if cm[1, 1] + cm[1, 0] > 0:\n",
    "            tpr = cm[1, 1] / (cm[1, 1] + cm[1, 0])\n",
    "        else:\n",
    "            tpr = 0\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"KNN with K={k}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Error Rate: {error_rate:.4f}\")\n",
    "        print(f\"True Positive Rate: {tpr:.1%}\")\n",
    "        print(f\"\\nConfusion Matrix:\")\n",
    "        print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on Caravan with Different Cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Caravan' in locals():\n",
    "    # Fit logistic regression\n",
    "    log_reg_car = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    log_reg_car.fit(X_train_car, y_train_car)\n",
    "    \n",
    "    # Get probabilities\n",
    "    y_probs_car = log_reg_car.predict_proba(X_test_car)[:, 1]\n",
    "    \n",
    "    # Test different cutoffs\n",
    "    cutoffs = [0.5, 0.25]\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        y_pred_car = (y_probs_car > cutoff).astype(int)\n",
    "        cm = confusion_matrix(y_test_car, y_pred_car)\n",
    "        \n",
    "        # True Positive Rate\n",
    "        if cm[1, 1] + cm[1, 0] > 0:\n",
    "            tpr = cm[1, 1] / (cm[1, 1] + cm[1, 0])\n",
    "        else:\n",
    "            tpr = 0\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Logistic Regression with cutoff = {cutoff}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"True Positive Rate: {tpr:.1%}\")\n",
    "        print(f\"\\nConfusion Matrix:\")\n",
    "        print(cm)\n",
    "        print(f\"\\nInterpretation: {tpr:.1%} of actual buyers were correctly identified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered:\n",
    "- **Logistic Regression**: Binary classification with probability outputs\n",
    "- **LDA**: Assumes Gaussian distributions with common covariance\n",
    "- **QDA**: Allows different covariances for each class (non-linear boundaries)\n",
    "- **KNN**: Non-parametric method based on nearest neighbors\n",
    "- **Feature Scaling**: Critical for distance-based methods like KNN\n",
    "- **Confusion Matrix**: Evaluating classification performance\n",
    "- **Threshold Tuning**: Adjusting decision boundaries for imbalanced data\n",
    "\n",
    "**Key Takeaways:**\n",
    "- No single model is always best - depends on data\n",
    "- Feature scaling is crucial for KNN and other distance-based methods\n",
    "- For imbalanced data, accuracy alone is misleading - look at precision/recall\n",
    "- Lower cutoffs can improve sensitivity at cost of specificity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}