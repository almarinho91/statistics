{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)\n",
    "\n",
    "Linear and non-linear classification using support vector machines.\n",
    "\n",
    "## Contents\n",
    "1. Linear SVM (Support Vector Classifier)\n",
    "2. Hyperparameter Tuning (Cost Parameter)\n",
    "3. Non-Linear SVM (Radial Kernel)\n",
    "4. ROC Curves\n",
    "5. Multi-Class SVM\n",
    "6. Application to Gene Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear SVM (Support Vector Classifier)\n",
    "\n",
    "Find the hyperplane that best separates two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(1)\n",
    "\n",
    "# Create 20 observations in 2 dimensions\n",
    "X = np.random.randn(20, 2)\n",
    "y = np.array([-1]*10 + [1]*10)\n",
    "\n",
    "# Shift positive class slightly\n",
    "X[y == 1] = X[y == 1] + 1\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y + 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[y == -1, 0], X[y == -1, 1], c='red', s=100, marker='o', \n",
    "           edgecolors='black', label='Class -1')\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', s=100, marker='s', \n",
    "           edgecolors='black', label='Class +1')\n",
    "plt.xlabel('X1', fontsize=12)\n",
    "plt.ylabel('X2', fontsize=12)\n",
    "plt.title('Training Data (not linearly separable)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Linear SVM with cost=10\n",
    "svm_linear = SVC(kernel='linear', C=10)\n",
    "svm_linear.fit(X, y)\n",
    "\n",
    "print(f\"Linear SVM (C=10):\")\n",
    "print(f\"Number of support vectors: {len(svm_linear.support_)}\")\n",
    "print(f\"Support vector indices: {svm_linear.support_}\")\n",
    "print(f\"Training accuracy: {svm_linear.score(X, y):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision boundary\n",
    "def plot_svm_decision_boundary(X, y, model, title=''):\n",
    "    \"\"\"\n",
    "    Plot SVM decision boundary and support vectors.\n",
    "    \"\"\"\n",
    "    # Create mesh\n",
    "    h = 0.02  # step size\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Predict on mesh\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, levels=[-1, 0, 1], colors=['red', 'blue'])\n",
    "    plt.contour(xx, yy, Z, levels=[0], colors='black', linewidths=2)\n",
    "    \n",
    "    # Plot data points\n",
    "    plt.scatter(X[y == -1, 0], X[y == -1, 1], c='red', s=100, marker='o',\n",
    "               edgecolors='black', label='Class -1')\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', s=100, marker='s',\n",
    "               edgecolors='black', label='Class +1')\n",
    "    \n",
    "    # Highlight support vectors\n",
    "    plt.scatter(X[model.support_, 0], X[model.support_, 1], \n",
    "               s=300, facecolors='none', edgecolors='yellow', linewidths=3,\n",
    "               label='Support Vectors')\n",
    "    \n",
    "    plt.xlabel('X1', fontsize=12)\n",
    "    plt.ylabel('X2', fontsize=12)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_svm_decision_boundary(X, y, svm_linear, 'Linear SVM (C=10)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Support vectors (yellow circles): {len(svm_linear.support_)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Cost Parameter (C)\n",
    "\n",
    "- **Large C**: Hard margin, fewer support vectors, more sensitive to outliers\n",
    "- **Small C**: Soft margin, more support vectors, more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with smaller cost (C=0.1)\n",
    "svm_small_c = SVC(kernel='linear', C=0.1)\n",
    "svm_small_c.fit(X, y)\n",
    "\n",
    "print(f\"Linear SVM (C=0.1):\")\n",
    "print(f\"Number of support vectors: {len(svm_small_c.support_)}\")\n",
    "print(f\"Support vector indices: {svm_small_c.support_}\")\n",
    "print(f\"Training accuracy: {svm_small_c.score(X, y):.4f}\")\n",
    "\n",
    "print(f\"\\nWith smaller C, number of support vectors increases: {len(svm_linear.support_)} → {len(svm_small_c.support_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare decision boundaries\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_svm_decision_boundary(X, y, svm_linear, 'Linear SVM (C=10, hard margin)')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_svm_decision_boundary(X, y, svm_small_c, 'Linear SVM (C=0.1, soft margin)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation: Smaller C creates wider margin with more support vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Tuning with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for best C\n",
    "np.random.seed(1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 5, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(kernel='linear'), param_grid, cv=10, \n",
    "                          scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Grid Search Results:\")\n",
    "print(f\"\\nBest C: {grid_search.best_params_['C']}\")\n",
    "print(f\"Best CV accuracy: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV results\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(results['param_C'], results['mean_train_score'], \n",
    "            marker='o', label='Train', linewidth=2, markersize=8)\n",
    "plt.semilogx(results['param_C'], results['mean_test_score'], \n",
    "            marker='s', label='CV (10-fold)', linewidth=2, markersize=8)\n",
    "plt.xlabel('Cost (C)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Cross-Validation: Accuracy vs Cost', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest model has C = {grid_search.best_params_['C']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "np.random.seed(2)\n",
    "X_test = np.random.randn(20, 2)\n",
    "y_test = np.random.choice([-1, 1], 20)\n",
    "X_test[y_test == 1] = X_test[y_test == 1] + 1\n",
    "\n",
    "# Predict with best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = (y_test == y_pred).mean()\n",
    "\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(cm,\n",
    "                   index=['Actual: -1', 'Actual: +1'],\n",
    "                   columns=['Predicted: -1', 'Predicted: +1']))\n",
    "print(f\"\\nTest Accuracy: {accuracy:.4f} ({accuracy*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Non-Linear SVM (Radial Basis Function Kernel)\n",
    "\n",
    "Use RBF kernel for non-linearly separable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate non-linearly separable data\n",
    "np.random.seed(1)\n",
    "\n",
    "X_nl = np.random.randn(200, 2)\n",
    "X_nl[:100] = X_nl[:100] + 2  # Shift first 100 points\n",
    "X_nl[100:150] = X_nl[100:150] - 2  # Shift next 50 points\n",
    "\n",
    "y_nl = np.array([1]*150 + [2]*50)\n",
    "\n",
    "print(f\"Dataset shape: {X_nl.shape}\")\n",
    "print(f\"Class distribution: Class 1: {(y_nl == 1).sum()}, Class 2: {(y_nl == 2).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize non-linear data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_nl[y_nl == 1, 0], X_nl[y_nl == 1, 1], \n",
    "           c='red', s=50, alpha=0.6, label='Class 1')\n",
    "plt.scatter(X_nl[y_nl == 2, 0], X_nl[y_nl == 2, 1], \n",
    "           c='blue', s=50, alpha=0.6, label='Class 2')\n",
    "plt.xlabel('X1', fontsize=12)\n",
    "plt.ylabel('X2', fontsize=12)\n",
    "plt.title('Non-Linearly Separable Data', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Data is NOT linearly separable - need non-linear kernel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "np.random.seed(1)\n",
    "train_idx = np.random.choice(200, 100, replace=False)\n",
    "test_idx = np.array([i for i in range(200) if i not in train_idx])\n",
    "\n",
    "X_train_nl = X_nl[train_idx]\n",
    "y_train_nl = y_nl[train_idx]\n",
    "X_test_nl = X_nl[test_idx]\n",
    "y_test_nl = y_nl[test_idx]\n",
    "\n",
    "print(f\"Training set: {len(X_train_nl)}\")\n",
    "print(f\"Test set: {len(X_test_nl)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit RBF kernel SVM with gamma=1, C=1\n",
    "svm_rbf = SVC(kernel='rbf', gamma=1, C=1)\n",
    "svm_rbf.fit(X_train_nl, y_train_nl)\n",
    "\n",
    "print(f\"RBF SVM (gamma=1, C=1):\")\n",
    "print(f\"Number of support vectors: {len(svm_rbf.support_)}\")\n",
    "print(f\"Training accuracy: {svm_rbf.score(X_train_nl, y_train_nl):.4f}\")\n",
    "print(f\"Test accuracy: {svm_rbf.score(X_test_nl, y_test_nl):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RBF decision boundary\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_svm_decision_boundary(X_train_nl, y_train_nl, svm_rbf, \n",
    "                          'RBF SVM (gamma=1, C=1) - Training Data')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Non-linear decision boundary captures circular pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Cost on Non-Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with very large C (overfitting)\n",
    "svm_rbf_large_c = SVC(kernel='rbf', gamma=1, C=1000)\n",
    "svm_rbf_large_c.fit(X_train_nl, y_train_nl)\n",
    "\n",
    "print(f\"RBF SVM (gamma=1, C=1000):\")\n",
    "print(f\"Number of support vectors: {len(svm_rbf_large_c.support_)}\")\n",
    "print(f\"Training accuracy: {svm_rbf_large_c.score(X_train_nl, y_train_nl):.4f}\")\n",
    "print(f\"Test accuracy: {svm_rbf_large_c.score(X_test_nl, y_test_nl):.4f}\")\n",
    "\n",
    "print(f\"\\nWith larger C: fewer support vectors ({len(svm_rbf_large_c.support_)} vs {len(svm_rbf.support_)})\")\n",
    "print(f\"Training accuracy improves, but may overfit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare decision boundaries\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "plot_svm_decision_boundary(X_train_nl, y_train_nl, svm_rbf, \n",
    "                          'RBF SVM (C=1, flexible)')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plot_svm_decision_boundary(X_train_nl, y_train_nl, svm_rbf_large_c, \n",
    "                          'RBF SVM (C=1000, very flexible)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Large C creates more complex boundary (risk of overfitting)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Both C and Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search over C and gamma\n",
    "np.random.seed(1)\n",
    "\n",
    "param_grid_rbf = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'gamma': [0.5, 1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "grid_search_rbf = GridSearchCV(SVC(kernel='rbf'), param_grid_rbf, cv=10,\n",
    "                              scoring='accuracy', return_train_score=True)\n",
    "grid_search_rbf.fit(X_train_nl, y_train_nl)\n",
    "\n",
    "print(\"Grid Search Results (RBF Kernel):\")\n",
    "print(f\"\\nBest parameters: C={grid_search_rbf.best_params_['C']}, gamma={grid_search_rbf.best_params_['gamma']}\")\n",
    "print(f\"Best CV accuracy: {grid_search_rbf.best_score_:.4f}\")\n",
    "\n",
    "# Test accuracy\n",
    "best_rbf = grid_search_rbf.best_estimator_\n",
    "test_acc_rbf = best_rbf.score(X_test_nl, y_test_nl)\n",
    "print(f\"Test accuracy: {test_acc_rbf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of CV accuracy\n",
    "results_rbf = pd.DataFrame(grid_search_rbf.cv_results_)\n",
    "pivot_table = results_rbf.pivot_table(values='mean_test_score', \n",
    "                                     index='param_gamma', \n",
    "                                     columns='param_C')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_table, annot=True, fmt='.3f', cmap='viridis', \n",
    "           cbar_kws={'label': 'CV Accuracy'})\n",
    "plt.xlabel('C', fontsize=12)\n",
    "plt.ylabel('Gamma', fontsize=12)\n",
    "plt.title('Grid Search: CV Accuracy for Different C and Gamma', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix on test set\n",
    "y_pred_rbf = best_rbf.predict(X_test_nl)\n",
    "cm_rbf = confusion_matrix(y_test_nl, y_pred_rbf)\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test Set):\")\n",
    "print(pd.DataFrame(cm_rbf,\n",
    "                   index=['Actual: 1', 'Actual: 2'],\n",
    "                   columns=['Predicted: 1', 'Predicted: 2']))\n",
    "print(f\"\\nTest Accuracy: {test_acc_rbf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ROC Curves\n",
    "\n",
    "Evaluate classifier performance across different thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit two models with different gamma\n",
    "svm_opt = SVC(kernel='rbf', gamma=2, C=1, probability=True)\n",
    "svm_opt.fit(X_train_nl, y_train_nl)\n",
    "\n",
    "svm_flex = SVC(kernel='rbf', gamma=50, C=1, probability=True)\n",
    "svm_flex.fit(X_train_nl, y_train_nl)\n",
    "\n",
    "print(f\"Model 1 (gamma=2): Train acc = {svm_opt.score(X_train_nl, y_train_nl):.4f}\")\n",
    "print(f\"Model 2 (gamma=50): Train acc = {svm_flex.score(X_train_nl, y_train_nl):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get decision function scores (distance from decision boundary)\n",
    "train_scores_opt = svm_opt.decision_function(X_train_nl)\n",
    "train_scores_flex = svm_flex.decision_function(X_train_nl)\n",
    "\n",
    "test_scores_opt = svm_opt.decision_function(X_test_nl)\n",
    "test_scores_flex = svm_flex.decision_function(X_test_nl)\n",
    "\n",
    "# Compute ROC curves\n",
    "fpr_train_opt, tpr_train_opt, _ = roc_curve(y_train_nl, train_scores_opt, pos_label=2)\n",
    "fpr_train_flex, tpr_train_flex, _ = roc_curve(y_train_nl, train_scores_flex, pos_label=2)\n",
    "\n",
    "fpr_test_opt, tpr_test_opt, _ = roc_curve(y_test_nl, test_scores_opt, pos_label=2)\n",
    "fpr_test_flex, tpr_test_flex, _ = roc_curve(y_test_nl, test_scores_flex, pos_label=2)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_train_opt = auc(fpr_train_opt, tpr_train_opt)\n",
    "auc_train_flex = auc(fpr_train_flex, tpr_train_flex)\n",
    "auc_test_opt = auc(fpr_test_opt, tpr_test_opt)\n",
    "auc_test_flex = auc(fpr_test_flex, tpr_test_flex)\n",
    "\n",
    "print(f\"\\nAUC Scores:\")\n",
    "print(f\"  Train - gamma=2: {auc_train_opt:.4f}\")\n",
    "print(f\"  Train - gamma=50: {auc_train_flex:.4f}\")\n",
    "print(f\"  Test - gamma=2: {auc_test_opt:.4f}\")\n",
    "print(f\"  Test - gamma=50: {auc_test_flex:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Training ROC\n",
    "axes[0].plot(fpr_train_opt, tpr_train_opt, 'b-', linewidth=2, \n",
    "            label=f'gamma=2 (AUC={auc_train_opt:.3f})')\n",
    "axes[0].plot(fpr_train_flex, tpr_train_flex, 'r-', linewidth=2, \n",
    "            label=f'gamma=50 (AUC={auc_train_flex:.3f})')\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "axes[0].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[0].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[0].set_title('ROC Curve - Training Data', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test ROC\n",
    "axes[1].plot(fpr_test_opt, tpr_test_opt, 'b-', linewidth=2, \n",
    "            label=f'gamma=2 (AUC={auc_test_opt:.3f})')\n",
    "axes[1].plot(fpr_test_flex, tpr_test_flex, 'r-', linewidth=2, \n",
    "            label=f'gamma=50 (AUC={auc_test_flex:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random')\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curve - Test Data', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: gamma=2 generalizes better (higher test AUC)\")\n",
    "print(\"gamma=50 overfits (high train AUC, lower test AUC)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Class SVM\n",
    "\n",
    "SVM can handle more than 2 classes using one-vs-one or one-vs-rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add third class to data\n",
    "np.random.seed(1)\n",
    "\n",
    "# Generate new class\n",
    "X_class3 = np.random.randn(50, 2)\n",
    "X_class3[:, 1] = X_class3[:, 1] + 2\n",
    "\n",
    "# Combine with existing data\n",
    "X_multi = np.vstack([X_nl, X_class3])\n",
    "y_multi = np.concatenate([y_nl, np.array([0]*50)])\n",
    "\n",
    "print(f\"Multi-class dataset shape: {X_multi.shape}\")\n",
    "print(f\"Class distribution:\")\n",
    "for cls in np.unique(y_multi):\n",
    "    print(f\"  Class {cls}: {(y_multi == cls).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multi-class data\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green', 'red', 'blue']\n",
    "for cls, color in zip([0, 1, 2], colors):\n",
    "    mask = y_multi == cls\n",
    "    plt.scatter(X_multi[mask, 0], X_multi[mask, 1], \n",
    "               c=color, s=50, alpha=0.6, label=f'Class {cls}')\n",
    "plt.xlabel('X1', fontsize=12)\n",
    "plt.ylabel('X2', fontsize=12)\n",
    "plt.title('Multi-Class Data (3 classes)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit multi-class SVM\n",
    "svm_multi = SVC(kernel='rbf', C=10, gamma=1)\n",
    "svm_multi.fit(X_multi, y_multi)\n",
    "\n",
    "print(f\"Multi-Class SVM:\")\n",
    "print(f\"Number of support vectors: {len(svm_multi.support_)}\")\n",
    "print(f\"Support vectors per class: {svm_multi.n_support_}\")\n",
    "print(f\"Training accuracy: {svm_multi.score(X_multi, y_multi):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multi-class decision boundaries\n",
    "h = 0.02\n",
    "x_min, x_max = X_multi[:, 0].min() - 1, X_multi[:, 0].max() + 1\n",
    "y_min, y_max = X_multi[:, 1].min() - 1, X_multi[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = svm_multi.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, levels=[0, 1, 2, 3], \n",
    "            colors=['green', 'red', 'blue'])\n",
    "\n",
    "for cls, color in zip([0, 1, 2], colors):\n",
    "    mask = y_multi == cls\n",
    "    plt.scatter(X_multi[mask, 0], X_multi[mask, 1], \n",
    "               c=color, s=50, edgecolors='black', label=f'Class {cls}')\n",
    "\n",
    "plt.scatter(X_multi[svm_multi.support_, 0], X_multi[svm_multi.support_, 1],\n",
    "           s=300, facecolors='none', edgecolors='yellow', linewidths=3,\n",
    "           label='Support Vectors')\n",
    "\n",
    "plt.xlabel('X1', fontsize=12)\n",
    "plt.ylabel('X2', fontsize=12)\n",
    "plt.title('Multi-Class SVM Decision Boundaries', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Application to Gene Expression Data\n",
    "\n",
    "High-dimensional data: many features (genes), few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Khan dataset (or create synthetic high-dimensional data)\n",
    "# Khan dataset has ~2000 genes (features), ~80 samples\n",
    "\n",
    "try:\n",
    "    # Try loading from sklearn datasets (if available)\n",
    "    from sklearn.datasets import load_svmlight_file\n",
    "    print(\"Note: Using synthetic high-dimensional data\")\n",
    "    print(\"Real Khan dataset requires specific download\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create synthetic gene expression data\n",
    "np.random.seed(1)\n",
    "\n",
    "# Training data: 63 samples, 2308 genes\n",
    "n_train = 63\n",
    "n_features = 2308\n",
    "X_train_gene = np.random.randn(n_train, n_features) * 0.5\n",
    "\n",
    "# 4 cancer types (0, 1, 2, 3)\n",
    "y_train_gene = np.array([0]*8 + [1]*23 + [2]*12 + [3]*20)\n",
    "\n",
    "# Add signal to features for different classes\n",
    "for cls in range(4):\n",
    "    mask = y_train_gene == cls\n",
    "    X_train_gene[mask, cls*500:(cls+1)*500] += np.random.randn(mask.sum(), 500) * 2\n",
    "\n",
    "# Test data: 20 samples\n",
    "n_test = 20\n",
    "X_test_gene = np.random.randn(n_test, n_features) * 0.5\n",
    "y_test_gene = np.array([0]*3 + [1]*6 + [2]*6 + [3]*5)\n",
    "\n",
    "for cls in range(4):\n",
    "    mask = y_test_gene == cls\n",
    "    X_test_gene[mask, cls*500:(cls+1)*500] += np.random.randn(mask.sum(), 500) * 2\n",
    "\n",
    "print(f\"Gene Expression Data:\")\n",
    "print(f\"Training: {X_train_gene.shape} ({n_train} samples, {n_features} genes)\")\n",
    "print(f\"Test: {X_test_gene.shape}\")\n",
    "print(f\"\\nTraining class distribution: {np.bincount(y_train_gene)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test_gene)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear SVM (linear kernel works well for high-dimensional data)\n",
    "svm_gene = SVC(kernel='linear', C=10)\n",
    "svm_gene.fit(X_train_gene, y_train_gene)\n",
    "\n",
    "print(f\"Linear SVM on Gene Expression Data:\")\n",
    "print(f\"Number of support vectors: {len(svm_gene.support_)}\")\n",
    "print(f\"Training accuracy: {svm_gene.score(X_train_gene, y_train_gene):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training confusion matrix\n",
    "y_pred_train_gene = svm_gene.predict(X_train_gene)\n",
    "cm_train_gene = confusion_matrix(y_train_gene, y_pred_train_gene)\n",
    "\n",
    "print(\"Training Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm_train_gene,\n",
    "                   index=[f'Actual: {i}' for i in range(4)],\n",
    "                   columns=[f'Predicted: {i}' for i in range(4)]))\n",
    "print(f\"\\nTraining errors: {(y_train_gene != y_pred_train_gene).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set evaluation\n",
    "y_pred_test_gene = svm_gene.predict(X_test_gene)\n",
    "cm_test_gene = confusion_matrix(y_test_gene, y_pred_test_gene)\n",
    "test_acc_gene = (y_test_gene == y_pred_test_gene).mean()\n",
    "\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(pd.DataFrame(cm_test_gene,\n",
    "                   index=[f'Actual: {i}' for i in range(4)],\n",
    "                   columns=[f'Predicted: {i}' for i in range(4)]))\n",
    "print(f\"\\nTest accuracy: {test_acc_gene:.4f}\")\n",
    "print(f\"Test errors: {(y_test_gene != y_pred_test_gene).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_test_gene, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=[f'Class {i}' for i in range(4)],\n",
    "           yticklabels=[f'Class {i}' for i in range(4)],\n",
    "           cbar_kws={'label': 'Count'})\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.title('Gene Expression: Test Set Confusion Matrix', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey Insight: Linear SVM works very well for high-dimensional data!\")\n",
    "print(f\"With p >> n (features >> samples), data is often linearly separable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered:\n",
    "\n",
    "### **Linear SVM (Support Vector Classifier)**\n",
    "- Find maximum margin hyperplane\n",
    "- **Support vectors**: Points on or inside margin\n",
    "- **Cost (C)**: Trade-off between margin width and violations\n",
    "  - Large C: Hard margin, few support vectors\n",
    "  - Small C: Soft margin, more support vectors\n",
    "\n",
    "### **Non-Linear SVM (Kernel Trick)**\n",
    "- **RBF Kernel**: K(x, x') = exp(-γ||x - x'||²)\n",
    "- **Gamma (γ)**: Controls decision boundary complexity\n",
    "  - Small γ: Smooth boundary (underfit)\n",
    "  - Large γ: Wiggly boundary (overfit)\n",
    "- **Polynomial, sigmoid** kernels also available\n",
    "\n",
    "### **Hyperparameter Tuning**\n",
    "- Use **cross-validation** to select C and γ\n",
    "- Grid search over parameter space\n",
    "- Balance training and test performance\n",
    "\n",
    "### **Multi-Class SVM**\n",
    "- **One-vs-One**: K(K-1)/2 binary classifiers\n",
    "- **One-vs-Rest**: K binary classifiers\n",
    "- sklearn uses one-vs-one by default\n",
    "\n",
    "### **High-Dimensional Data**\n",
    "- When p >> n, **linear kernel** often sufficient\n",
    "- Data becomes linearly separable in high dimensions\n",
    "- Avoid overfitting with proper C selection\n",
    "\n",
    "### **Key Takeaways**\n",
    "- SVMs find optimal decision boundary (maximum margin)\n",
    "- Kernel trick enables non-linear boundaries\n",
    "- Tuning C and γ is crucial\n",
    "- Works well for high-dimensional data\n",
    "- Robust to outliers (soft margin)\n",
    "- **Less interpretable** than trees/linear regression\n",
    "- **Computationally expensive** for large n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}