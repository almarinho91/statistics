{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Regularization\n",
    "\n",
    "Methods for selecting the best subset of predictors in linear regression.\n",
    "\n",
    "## Contents\n",
    "1. Best Subset Selection\n",
    "2. Model Selection Criteria (RSS, R², Adjusted R², Cp, BIC)\n",
    "3. Forward and Backward Stepwise Selection\n",
    "4. Validation Set Approach\n",
    "5. K-Fold Cross-Validation for Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Hitters Dataset\n",
    "\n",
    "Baseball players' salaries and performance statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hitters dataset\n",
    "url = \"https://raw.githubusercontent.com/selva86/datasets/master/Hitters.csv\"\n",
    "Hitters = pd.read_csv(url)\n",
    "\n",
    "print(f\"Dataset shape: {Hitters.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(Hitters.columns.tolist())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "Hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(Hitters.isnull().sum())\n",
    "print(f\"\\nTotal missing values in Salary: {Hitters['Salary'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing Salary\n",
    "Hitters = Hitters.dropna()\n",
    "\n",
    "print(f\"Dataset shape after removing NAs: {Hitters.shape}\")\n",
    "print(f\"Total missing values: {Hitters.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data summary\n",
    "print(\"Summary statistics:\")\n",
    "Hitters.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Best Subset Selection\n",
    "\n",
    "Try all possible combinations of predictors and select the best model for each size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "# Convert categorical variables to dummy variables\n",
    "X = pd.get_dummies(Hitters.drop('Salary', axis=1), drop_first=True)\n",
    "y = Hitters['Salary']\n",
    "\n",
    "print(f\"Number of predictors: {X.shape[1]}\")\n",
    "print(f\"Predictor names: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_subset_selection(X, y, max_features=None):\n",
    "    \"\"\"\n",
    "    Perform best subset selection.\n",
    "    \n",
    "    For each model size k, find the best k-variable model.\n",
    "    \"\"\"\n",
    "    if max_features is None:\n",
    "        max_features = X.shape[1]\n",
    "    \n",
    "    n = len(y)\n",
    "    results = []\n",
    "    \n",
    "    for k in range(1, max_features + 1):\n",
    "        print(f\"\\rEvaluating models with {k} predictors...\", end='')\n",
    "        \n",
    "        best_rss = np.inf\n",
    "        best_features = None\n",
    "        best_r2 = -np.inf\n",
    "        \n",
    "        # Try all combinations of k features\n",
    "        for features in combinations(X.columns, k):\n",
    "            X_subset = X[list(features)]\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_subset, y)\n",
    "            y_pred = model.predict(X_subset)\n",
    "            \n",
    "            rss = np.sum((y - y_pred) ** 2)\n",
    "            r2 = r2_score(y, y_pred)\n",
    "            \n",
    "            if rss < best_rss:\n",
    "                best_rss = rss\n",
    "                best_features = features\n",
    "                best_r2 = r2\n",
    "                best_model = model\n",
    "        \n",
    "        # Calculate other metrics\n",
    "        p = k\n",
    "        adj_r2 = 1 - (1 - best_r2) * (n - 1) / (n - p - 1)\n",
    "        \n",
    "        # Cp (Mallows' Cp)\n",
    "        mse_full = best_rss / n  # Using current model's MSE as estimate\n",
    "        cp = (best_rss / mse_full) - n + 2 * p\n",
    "        \n",
    "        # BIC\n",
    "        bic = n * np.log(best_rss / n) + p * np.log(n)\n",
    "        \n",
    "        results.append({\n",
    "            'n_features': k,\n",
    "            'features': best_features,\n",
    "            'rss': best_rss,\n",
    "            'r2': best_r2,\n",
    "            'adj_r2': adj_r2,\n",
    "            'cp': cp,\n",
    "            'bic': bic,\n",
    "            'model': best_model\n",
    "        })\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Note: For large datasets, this is computationally expensive!\n",
    "# We'll limit to 8 features for demonstration\n",
    "print(\"Running best subset selection (limited to 8 features for speed)...\")\n",
    "best_subset_results = best_subset_selection(X, y, max_features=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST SUBSET SELECTION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "display_cols = ['n_features', 'rss', 'r2', 'adj_r2', 'cp', 'bic']\n",
    "print(best_subset_results[display_cols].round(4))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Selection Criteria\n",
    "\n",
    "Plot different criteria to choose optimal model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot selection criteria\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# RSS\n",
    "axes[0, 0].plot(best_subset_results['n_features'], best_subset_results['rss'], \n",
    "                marker='o', linewidth=2, markersize=6)\n",
    "axes[0, 0].set_xlabel('Number of Variables')\n",
    "axes[0, 0].set_ylabel('RSS')\n",
    "axes[0, 0].set_title('Residual Sum of Squares')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Adjusted R²\n",
    "best_idx_adjr2 = best_subset_results['adj_r2'].idxmax()\n",
    "axes[0, 1].plot(best_subset_results['n_features'], best_subset_results['adj_r2'], \n",
    "                marker='o', linewidth=2, markersize=6)\n",
    "axes[0, 1].scatter(best_subset_results.loc[best_idx_adjr2, 'n_features'], \n",
    "                   best_subset_results.loc[best_idx_adjr2, 'adj_r2'], \n",
    "                   color='red', s=200, zorder=5, label=f\"Best: {best_subset_results.loc[best_idx_adjr2, 'n_features']} vars\")\n",
    "axes[0, 1].set_xlabel('Number of Variables')\n",
    "axes[0, 1].set_ylabel('Adjusted R²')\n",
    "axes[0, 1].set_title('Adjusted R²')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Cp\n",
    "best_idx_cp = best_subset_results['cp'].idxmin()\n",
    "axes[1, 0].plot(best_subset_results['n_features'], best_subset_results['cp'], \n",
    "                marker='o', linewidth=2, markersize=6)\n",
    "axes[1, 0].scatter(best_subset_results.loc[best_idx_cp, 'n_features'], \n",
    "                   best_subset_results.loc[best_idx_cp, 'cp'], \n",
    "                   color='red', s=200, zorder=5, label=f\"Best: {best_subset_results.loc[best_idx_cp, 'n_features']} vars\")\n",
    "axes[1, 0].set_xlabel('Number of Variables')\n",
    "axes[1, 0].set_ylabel('Cp')\n",
    "axes[1, 0].set_title(\"Mallows' Cp\")\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# BIC\n",
    "best_idx_bic = best_subset_results['bic'].idxmin()\n",
    "axes[1, 1].plot(best_subset_results['n_features'], best_subset_results['bic'], \n",
    "                marker='o', linewidth=2, markersize=6)\n",
    "axes[1, 1].scatter(best_subset_results.loc[best_idx_bic, 'n_features'], \n",
    "                   best_subset_results.loc[best_idx_bic, 'bic'], \n",
    "                   color='red', s=200, zorder=5, label=f\"Best: {best_subset_results.loc[best_idx_bic, 'n_features']} vars\")\n",
    "axes[1, 1].set_xlabel('Number of Variables')\n",
    "axes[1, 1].set_ylabel('BIC')\n",
    "axes[1, 1].set_title('Bayesian Information Criterion')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest model by Adjusted R²: {best_subset_results.loc[best_idx_adjr2, 'n_features']} variables\")\n",
    "print(f\"Best model by Cp: {best_subset_results.loc[best_idx_cp, 'n_features']} variables\")\n",
    "print(f\"Best model by BIC: {best_subset_results.loc[best_idx_bic, 'n_features']} variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Forward and Backward Stepwise Selection\n",
    "\n",
    "More efficient alternatives to best subset selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_stepwise_selection(X, y, max_features=None):\n",
    "    \"\"\"\n",
    "    Forward stepwise selection: Start with no variables, add one at a time.\n",
    "    \"\"\"\n",
    "    if max_features is None:\n",
    "        max_features = X.shape[1]\n",
    "    \n",
    "    remaining = set(X.columns)\n",
    "    selected = []\n",
    "    results = []\n",
    "    \n",
    "    for k in range(1, max_features + 1):\n",
    "        print(f\"\\rForward step {k}...\", end='')\n",
    "        \n",
    "        best_rss = np.inf\n",
    "        best_feature = None\n",
    "        \n",
    "        for feature in remaining:\n",
    "            features = selected + [feature]\n",
    "            X_subset = X[features]\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_subset, y)\n",
    "            y_pred = model.predict(X_subset)\n",
    "            rss = np.sum((y - y_pred) ** 2)\n",
    "            \n",
    "            if rss < best_rss:\n",
    "                best_rss = rss\n",
    "                best_feature = feature\n",
    "                best_model = model\n",
    "        \n",
    "        selected.append(best_feature)\n",
    "        remaining.remove(best_feature)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        X_subset = X[selected]\n",
    "        y_pred = best_model.predict(X_subset)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'n_features': k,\n",
    "            'features': tuple(selected),\n",
    "            'rss': best_rss,\n",
    "            'r2': r2\n",
    "        })\n",
    "    \n",
    "    print(\" Done!\")\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def backward_stepwise_selection(X, y):\n",
    "    \"\"\"\n",
    "    Backward stepwise selection: Start with all variables, remove one at a time.\n",
    "    \"\"\"\n",
    "    selected = list(X.columns)\n",
    "    results = []\n",
    "    \n",
    "    # Full model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    rss = np.sum((y - y_pred) ** 2)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'n_features': len(selected),\n",
    "        'features': tuple(selected),\n",
    "        'rss': rss,\n",
    "        'r2': r2\n",
    "    })\n",
    "    \n",
    "    while len(selected) > 1:\n",
    "        print(f\"\\rBackward step (removing from {len(selected)} vars)...\", end='')\n",
    "        \n",
    "        best_rss = np.inf\n",
    "        worst_feature = None\n",
    "        \n",
    "        for feature in selected:\n",
    "            features = [f for f in selected if f != feature]\n",
    "            X_subset = X[features]\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_subset, y)\n",
    "            y_pred = model.predict(X_subset)\n",
    "            rss = np.sum((y - y_pred) ** 2)\n",
    "            \n",
    "            if rss < best_rss:\n",
    "                best_rss = rss\n",
    "                worst_feature = feature\n",
    "                best_model = model\n",
    "        \n",
    "        selected.remove(worst_feature)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        X_subset = X[selected]\n",
    "        y_pred = best_model.predict(X_subset)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'n_features': len(selected),\n",
    "            'features': tuple(selected),\n",
    "            'rss': best_rss,\n",
    "            'r2': r2\n",
    "        })\n",
    "    \n",
    "    print(\" Done!\")\n",
    "    return pd.DataFrame(results).sort_values('n_features').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run forward and backward selection\n",
    "print(\"Running forward stepwise selection...\")\n",
    "forward_results = forward_stepwise_selection(X, y, max_features=8)\n",
    "\n",
    "print(\"\\nRunning backward stepwise selection...\")\n",
    "backward_results = backward_stepwise_selection(X)\n",
    "backward_results = backward_results[backward_results['n_features'] <= 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare methods\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: BEST SUBSET vs FORWARD vs BACKWARD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'n_features': best_subset_results['n_features'],\n",
    "    'Best_Subset_R2': best_subset_results['r2'],\n",
    "    'Forward_R2': forward_results['r2'],\n",
    "    'Backward_R2': backward_results['r2']\n",
    "})\n",
    "\n",
    "print(comparison.round(4))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(best_subset_results['n_features'], best_subset_results['r2'], \n",
    "         marker='o', label='Best Subset', linewidth=2, markersize=8)\n",
    "plt.plot(forward_results['n_features'], forward_results['r2'], \n",
    "         marker='s', label='Forward', linewidth=2, markersize=8)\n",
    "plt.plot(backward_results['n_features'], backward_results['r2'], \n",
    "         marker='^', label='Backward', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Variables')\n",
    "plt.ylabel('R²')\n",
    "plt.title('Comparison of Selection Methods')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "np.random.seed(1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward selection on training set\n",
    "forward_train_results = forward_stepwise_selection(X_train, y_train, max_features=X.shape[1])\n",
    "\n",
    "# Evaluate on test set\n",
    "val_errors = []\n",
    "\n",
    "for idx, row in forward_train_results.iterrows():\n",
    "    features = list(row['features'])\n",
    "    X_test_subset = X_test[features]\n",
    "    \n",
    "    # Refit model on training data with these features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train[features], y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_subset)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    val_errors.append(mse)\n",
    "\n",
    "forward_train_results['test_mse'] = val_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation errors\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(forward_train_results['n_features'], forward_train_results['test_mse'], \n",
    "         marker='o', linewidth=2, markersize=8)\n",
    "\n",
    "best_idx = forward_train_results['test_mse'].idxmin()\n",
    "plt.scatter(forward_train_results.loc[best_idx, 'n_features'], \n",
    "           forward_train_results.loc[best_idx, 'test_mse'], \n",
    "           color='red', s=200, zorder=5, \n",
    "           label=f\"Best: {forward_train_results.loc[best_idx, 'n_features']} variables\")\n",
    "\n",
    "plt.xlabel('Number of Variables')\n",
    "plt.ylabel('Test MSE')\n",
    "plt.title('Validation Set Approach')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest model has {forward_train_results.loc[best_idx, 'n_features']} variables\")\n",
    "print(f\"Test MSE: {forward_train_results.loc[best_idx, 'test_mse']:.4f}\")\n",
    "print(f\"\\nFeatures: {forward_train_results.loc[best_idx, 'features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-Fold Cross-Validation for Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "k = 10\n",
    "np.random.seed(1)\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "\n",
    "# Matrix to store CV errors\n",
    "cv_errors = np.zeros((k, X.shape[1]))\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\rProcessing fold {fold_idx + 1}/{k}...\", end='')\n",
    "    \n",
    "    X_train_fold = X.iloc[train_idx]\n",
    "    y_train_fold = y.iloc[train_idx]\n",
    "    X_test_fold = X.iloc[test_idx]\n",
    "    y_test_fold = y.iloc[test_idx]\n",
    "    \n",
    "    # Forward selection on this fold\n",
    "    fold_results = forward_stepwise_selection(X_train_fold, y_train_fold, max_features=X.shape[1])\n",
    "    \n",
    "    # Evaluate each model size\n",
    "    for idx, row in fold_results.iterrows():\n",
    "        features = list(row['features'])\n",
    "        \n",
    "        # Refit and predict\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_fold[features], y_train_fold)\n",
    "        y_pred = model.predict(X_test_fold[features])\n",
    "        mse = mean_squared_error(y_test_fold, y_pred)\n",
    "        \n",
    "        cv_errors[fold_idx, row['n_features'] - 1] = mse\n",
    "\n",
    "print(\" Done!\")\n",
    "\n",
    "# Calculate mean CV error for each model size\n",
    "mean_cv_errors = cv_errors.mean(axis=0)\n",
    "std_cv_errors = cv_errors.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV errors\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, X.shape[1] + 1), mean_cv_errors, marker='o', linewidth=2, markersize=8)\n",
    "plt.fill_between(range(1, X.shape[1] + 1), \n",
    "                 mean_cv_errors - std_cv_errors,\n",
    "                 mean_cv_errors + std_cv_errors,\n",
    "                 alpha=0.2)\n",
    "\n",
    "best_idx_cv = np.argmin(mean_cv_errors)\n",
    "plt.scatter(best_idx_cv + 1, mean_cv_errors[best_idx_cv], \n",
    "           color='red', s=200, zorder=5, label=f\"Best: {best_idx_cv + 1} variables\")\n",
    "\n",
    "plt.xlabel('Number of Variables')\n",
    "plt.ylabel('Cross-Validation MSE')\n",
    "plt.title(f'{k}-Fold Cross-Validation')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest model by {k}-Fold CV: {best_idx_cv + 1} variables\")\n",
    "print(f\"CV MSE: {mean_cv_errors[best_idx_cv]:.4f} ± {std_cv_errors[best_idx_cv]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final model on full dataset with optimal number of features\n",
    "final_results = forward_stepwise_selection(X, y, max_features=X.shape[1])\n",
    "best_features = list(final_results.iloc[best_idx_cv]['features'])\n",
    "\n",
    "print(f\"\\nFinal model with {len(best_features)} variables:\")\n",
    "print(best_features)\n",
    "\n",
    "# Fit and display coefficients\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X[best_features], y)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': best_features,\n",
    "    'Coefficient': final_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nCoefficients:\")\n",
    "print(coef_df)\n",
    "print(f\"\\nIntercept: {final_model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook covered:\n",
    "\n",
    "### **Best Subset Selection**\n",
    "- Try all possible combinations of predictors\n",
    "- Computationally expensive: 2^p models for p predictors\n",
    "- Guarantees finding the best model for each size\n",
    "\n",
    "### **Forward Stepwise Selection**\n",
    "- Start with no variables, add one at a time\n",
    "- Greedy algorithm: may not find global optimum\n",
    "- Much faster: only p(p+1)/2 models\n",
    "\n",
    "### **Backward Stepwise Selection**\n",
    "- Start with all variables, remove one at a time\n",
    "- Also greedy\n",
    "- Requires n > p (more observations than predictors)\n",
    "\n",
    "### **Selection Criteria**\n",
    "- **RSS**: Always decreases with more variables\n",
    "- **R²**: Always increases with more variables\n",
    "- **Adjusted R²**: Penalizes model complexity\n",
    "- **Cp**: Estimates test error\n",
    "- **BIC**: Stronger penalty than Cp\n",
    "\n",
    "### **Cross-Validation**\n",
    "- Most reliable method for model selection\n",
    "- Directly estimates test error\n",
    "- K=5 or K=10 are common choices\n",
    "\n",
    "### **Key Takeaways:**\n",
    "- More variables ≠ better model (overfitting!)\n",
    "- Use CV to select model size\n",
    "- Forward/backward are good approximations to best subset\n",
    "- Different criteria may suggest different model sizes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}